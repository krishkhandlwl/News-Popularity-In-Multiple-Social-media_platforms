{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3340ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2750e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_final=pd.read_csv(\"DataSet/News_Final.csv\")\n",
    "\n",
    "news_final.describe()\n",
    "print(news_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba35bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_final[[\"Facebook\",\"GooglePlus\",\"LinkedIn\"]] = news_final[[\"Facebook\",\"GooglePlus\",\"LinkedIn\"]] .replace(-1, np.NaN)\n",
    "news_final.dropna(inplace=True)\n",
    "print(news_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "#removing unnecessary punctuations and tags\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97704de",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_final['Title'] = np.vectorize(remove_pattern)(news_final['Title'], \"@[\\\\w]*\")\n",
    "\n",
    "#replacing numbers and other special characters with a space in the Title elements\n",
    "news_final['Title'] = news_final['Title'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "news_final['Headline'] = np.vectorize(remove_pattern)(news_final['Headline'], \"@[\\\\w]*\")\n",
    "news_final['Headline'] = news_final['Headline'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "#remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "news_final= pd.DataFrame(news_final)\n",
    "news_final['Title'] = news_final['Title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "news_final= pd.DataFrame(news_final)\n",
    "news_final['Headline'] = news_final['Headline'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b62365",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=[]\n",
    "z=list(zip(news_final['IDLink'],news_final['Title'],news_final['Headline'],news_final['Source'],news_final['Topic'],news_final['Facebook']))\n",
    "z1=sorted(z, key=lambda t: t[5])\n",
    "\n",
    "labels = ['IDLink','Title', 'Headline','Source', 'Topic', 'SharesOfFacebook']\n",
    "df_facebook = pd.DataFrame.from_records(z1, columns=labels)\n",
    "\n",
    "def label_emotion (row):\n",
    "   if row['SharesOfFacebook'] >=0 and row['SharesOfFacebook'] <=1050  :\n",
    "      return 1\n",
    "   if row['SharesOfFacebook'] > 1050 and row['SharesOfFacebook']<=15000:\n",
    "      return 2\n",
    "   if row['SharesOfFacebook'] > 15000 and row['SharesOfFacebook']<=20000:\n",
    "      return 3\n",
    "   if row['SharesOfFacebook'] >20000 and row['SharesOfFacebook'] <=50000:\n",
    "      return 4\n",
    "df_facebook['category_facebook'] = df_facebook.apply (lambda row: label_emotion (row),axis=1)\n",
    "\n",
    "df_facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=[]\n",
    "z=list(zip(news_final['IDLink'],news_final['Title'],news_final['Headline'],news_final['Source'],news_final['Topic'],news_final['GooglePlus']))\n",
    "\n",
    "z1=sorted(z, key=lambda t: t[5])\n",
    "\n",
    "labels = ['IDLink','Title', 'Headline','Source', 'Topic', 'SharesOfGooglePlus']\n",
    "df_googlePlus = pd.DataFrame.from_records(z1, columns=labels)\n",
    "\n",
    "def label_emotion (row):\n",
    "   if row['SharesOfGooglePlus'] >=0 and row['SharesOfGooglePlus'] <=40  :\n",
    "      return 1\n",
    "   if row['SharesOfGooglePlus'] > 40 and row['SharesOfGooglePlus']<=120:\n",
    "      return 2\n",
    "   if row['SharesOfGooglePlus'] > 120 and row['SharesOfGooglePlus']<=600:\n",
    "      return 3\n",
    "   if row['SharesOfGooglePlus'] >600 and row['SharesOfGooglePlus'] <=605:\n",
    "      return 4\n",
    "   if row['SharesOfGooglePlus'] >605 and row['SharesOfGooglePlus'] <=1500:\n",
    "      return 5\n",
    "\n",
    "df_googlePlus['category_GooglePlus'] = df_googlePlus.apply (lambda row: label_emotion (row),axis=1)\n",
    "\n",
    "df_googlePlus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63470c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z=[]\n",
    "z=list(zip(news_final['IDLink'],news_final['Title'],news_final['Headline'],news_final['Source'],news_final['Topic'],news_final['LinkedIn']))\n",
    "\n",
    "z1=sorted(z, key=lambda t: t[5])\n",
    "\n",
    "labels = ['IDLink','Title', 'Headline','Source', 'Topic', 'SharesOfLinkedIn']\n",
    "df_linkedIn = pd.DataFrame.from_records(z1, columns=labels)\n",
    "\n",
    "def label_emotion (row):\n",
    "   if row['SharesOfLinkedIn'] >=0 and row['SharesOfLinkedIn'] <=100  :\n",
    "      return 1\n",
    "   if row['SharesOfLinkedIn'] > 100 and row['SharesOfLinkedIn']<=2000:\n",
    "      return 2\n",
    "   if row['SharesOfLinkedIn'] > 2000 and row['SharesOfLinkedIn']<=6000:\n",
    "      return 3\n",
    "   if row['SharesOfLinkedIn'] >6000 and row['SharesOfLinkedIn'] <=6400:\n",
    "      return 4\n",
    "df_linkedIn['category_LinkedIn'] = df_linkedIn.apply (lambda row: label_emotion (row),axis=1)\n",
    "\n",
    "df_linkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "# integer encode the documents\n",
    "vocab_size = 100\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in df_facebook['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = max(encoded_docs, key = len)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "max_length = 5\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3367af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padded_docs\n",
    "y = df_facebook['category_facebook']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c586352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#Fit logistic regression to the training set\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d179d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22aac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af29f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749cd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d64f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "vocab_size = 100\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in df_googlePlus['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3793614",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = max(encoded_docs, key = len)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "max_length = 25\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x = padded_docs\n",
    "y = df_googlePlus['category_GooglePlus']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "#Fit logistic regression to the training set\n",
    "classifier = LogisticRegression(random_state=1)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set results and creating confusion matrix\n",
    "y_pred = classifier.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48997581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot#import has not been moved from here for better understandability of the code\n",
    "# integer encode the documents\n",
    "vocab_size = 100\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in df_linkedIn['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73fdd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = max(encoded_docs, key = len)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The sequences have different lengths and Keras prefers inputs to be vectorized and all inputs to have the same length. \n",
    "We will pad all input sequences to have the length of 4.\n",
    "Again, we can do this with a built in Keras function, in this case the pad_sequences() function.\n",
    "pad documents to a max length of 4 words\n",
    "\"\"\"\n",
    "from keras.utils import pad_sequences\n",
    "max_length = 25\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x = padded_docs\n",
    "y = df_linkedIn['category_LinkedIn']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "#Fit logistic regression to the training set\n",
    "classifier = LogisticRegression(random_state=1)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c031e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578781e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
